{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning facebook:wav2vec2-large-960h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we finetune the facebook:wav2vec2-large-960h model from huggingface using the `cv-valid-train` common_voice dataset. This notebook follows the finetuning framework from this [hugginface blog](https://huggingface.co/blog/fine-tune-wav2vec2-english) with minor adaptations. First, we import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tfc/anaconda3/envs/asr/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Audio as PlayAudio\n",
    "\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC, Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_dataset, Audio, DatasetDict, load_from_disk\n",
    "import evaluate\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchaudio\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import AdamW\n",
    "from torch.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import soundfile as sf\n",
    "\n",
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first convert all mp3 files to wav files, which the wav2vec2 model assumes. This may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to convert mp3 to wav\n",
    "# def convert_mp3_to_wav(mp3_file):\n",
    "#     # Generate the output wav file path\n",
    "#     wav_file = mp3_file.replace('.mp3', '.wav')\n",
    "    \n",
    "#     # Convert mp3 to wav if wav file does not exist\n",
    "#     if not os.path.exists(wav_file):\n",
    "#         waveform, sample_rate = torchaudio.load(mp3_file)\n",
    "#         torchaudio.save(wav_file, waveform, sample_rate)\n",
    "    \n",
    "#     return wav_file\n",
    "\n",
    "# # File locations assumed in parent directory\n",
    "# transcription_file = os.path.expanduser(\n",
    "#     '~/asr_project/common_voice/cv-valid-train.csv')              # Transcription file location\n",
    "# audio_folder = os.path.expanduser(\n",
    "#     '~/asr_project/common_voice/cv-valid-train')   # Audio files directory\n",
    "# df = pd.read_csv(transcription_file)[['filename','text']]         # Read transcription file\n",
    "\n",
    "# # Convert mp3 to wav. Change mp3 file extension in df accordingly\n",
    "# df['filename'] = df['filename'].apply(\n",
    "#     lambda filename: convert_mp3_to_wav(\n",
    "#         os.path.join(audio_folder, filename)))\n",
    "# df.to_csv('temp.csv',index=False)                                 # Save temp copy of csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a `DatasetDict` for pre-processing, following the approach in the [hugginface blog](https://huggingface.co/blog/fine-tune-wav2vec2-english) mentioned earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['filename', 'text'],\n",
       "        num_rows: 137043\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['filename', 'text'],\n",
       "        num_rows: 58733\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load csv file with wav filenames as dataset\n",
    "dataset = load_dataset('csv', data_files='temp.csv', split='train')\n",
    "dataset = dataset.cast_column(\"filename\",\n",
    "                              Audio(sampling_rate=16000))         # Cast audio files with 16kHz sampling rate\n",
    "\n",
    "# train-val 70-30 split\n",
    "dataset = dataset.train_test_split(test_size=0.3, seed=42)        # Split to train-val\n",
    "\n",
    "# Final, combined dataset\n",
    "dataset = DatasetDict({\n",
    "    'train': dataset['train'],\n",
    "    'val': dataset['test']})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first create a vocab required for a tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q': 0,\n",
       " 'n': 1,\n",
       " 'u': 2,\n",
       " 'l': 3,\n",
       " 'i': 4,\n",
       " 'h': 5,\n",
       " 's': 6,\n",
       " 'w': 7,\n",
       " 'g': 8,\n",
       " 'r': 9,\n",
       " 'y': 10,\n",
       " 'x': 11,\n",
       " 'e': 12,\n",
       " 'o': 13,\n",
       " 'd': 14,\n",
       " 'a': 15,\n",
       " 'p': 16,\n",
       " 'k': 17,\n",
       " \"'\": 18,\n",
       " 'b': 19,\n",
       " 'c': 20,\n",
       " ' ': 21,\n",
       " 'v': 22,\n",
       " 'z': 23,\n",
       " 't': 24,\n",
       " 'f': 25,\n",
       " 'm': 26,\n",
       " 'j': 27}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique characters across all splits and provide unique id.\n",
    "all_text_train = \" \".join(dataset[\"train\"][\"text\"])\n",
    "all_text_val = \" \".join(dataset[\"val\"][\"text\"])\n",
    "\n",
    "all_text = \" \".join([all_text_train, all_text_val])\n",
    "vocab = list(set(all_text))\n",
    "\n",
    "vocab_dict = {v: k for k, v in enumerate(vocab)}\n",
    "vocab_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# Creating special tokens\n",
    "vocab_dict[\"|\"] = vocab_dict[\" \"]\n",
    "del vocab_dict[\" \"]\n",
    "vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
    "vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
    "print(len(vocab_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving in json file.\n",
    "import json\n",
    "with open('vocab.json', 'w') as vocab_file:\n",
    "    json.dump(vocab_dict, vocab_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create the tokenizer using the vocab created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Wav2Vec2CTCTokenizer(\"./vocab.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the `feature_extractor`. We follow the instructions to use `return_attention_mask=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrap everything as a processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a quick check, play a random audio file below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she comes by it naturally\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_int = random.randint(0, len(dataset[\"train\"]))\n",
    "print(dataset[\"train\"][\"text\"][rand_int])\n",
    "\n",
    "audio_data = dataset[\"train\"][rand_int][\"filename\"][\"array\"]\n",
    "PlayAudio(data=audio_data, rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and check the data formats, e.g. 1-D waveform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target text: i heard a peculiar humming sound from the pit\n",
      "Input array shape: (72576,)\n",
      "Sampling rate: 16000\n"
     ]
    }
   ],
   "source": [
    "rand_int = random.randint(0, len(dataset[\"train\"]))\n",
    "\n",
    "print(\"Target text:\", dataset[\"train\"][rand_int][\"text\"])\n",
    "print(\"Input array shape:\", np.asarray(dataset[\"train\"][rand_int][\"filename\"][\"array\"]).shape)\n",
    "print(\"Sampling rate:\", dataset[\"train\"][rand_int][\"filename\"][\"sampling_rate\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we prepare the dataset into the format expected by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_dataset(batch):\n",
    "#     audio = batch[\"filename\"]\n",
    "\n",
    "#     # batched output is \"un-batched\" to ensure mapping is correct\n",
    "#     batch[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "    \n",
    "#     with processor.as_target_processor():\n",
    "#         batch[\"labels\"] = processor(batch[\"text\"]).input_ids\n",
    "#     return batch\n",
    "\n",
    "# dataset = dataset.map(prepare_dataset, remove_columns=dataset.column_names[\"train\"], num_proc=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the dataset to a directory\n",
    "# dataset.save_to_disk(\"temp_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As elaborated [here](https://huggingface.co/blog/fine-tune-wav2vec2-english), a data collator with dynamic padding is more efficient for ASR applications, considering the lengths of the input sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = load_from_disk(\"temp_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "        max_length (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
    "        max_length_labels (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "    max_length: Optional[int] = None\n",
    "    max_length_labels: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    pad_to_multiple_of_labels: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length_labels,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the WER metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_metric = evaluate.load(\"wer\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, loading the pre-trained model and setting up trainer so that we can begin finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/1500 [00:00<?, ?it/s]/home/tfc/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "  3%|         | 50/1500 [00:14<06:28,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.3456, 'grad_norm': 10.738499641418457, 'learning_rate': 4.8433333333333336e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 100/1500 [00:28<07:05,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.4887, 'grad_norm': 22.676118850708008, 'learning_rate': 4.676666666666667e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 150/1500 [00:43<06:12,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.4989, 'grad_norm': 7.022335529327393, 'learning_rate': 4.5100000000000005e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 200/1500 [00:57<06:36,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.6937, 'grad_norm': 10.28407096862793, 'learning_rate': 4.3433333333333336e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 250/1500 [01:12<07:49,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.4204, 'grad_norm': 1.9037978649139404, 'learning_rate': 4.176666666666667e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 17%|        | 250/1500 [01:15<07:49,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.385029315948486, 'eval_wer': 1.0, 'eval_runtime': 3.6403, 'eval_samples_per_second': 54.941, 'eval_steps_per_second': 6.868, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tfc/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      " 20%|        | 300/1500 [01:32<05:51,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.4364, 'grad_norm': 9.899394035339355, 'learning_rate': 4.0100000000000006e-05, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 350/1500 [01:47<05:06,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.2742, 'grad_norm': 7.543509483337402, 'learning_rate': 3.843333333333334e-05, 'epoch': 1.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 400/1500 [02:01<05:16,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.1096, 'grad_norm': 6.498869895935059, 'learning_rate': 3.676666666666667e-05, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 450/1500 [02:15<05:49,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.2477, 'grad_norm': 1.3148185014724731, 'learning_rate': 3.51e-05, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 500/1500 [02:29<04:03,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.8424, 'grad_norm': 11.746952056884766, 'learning_rate': 3.343333333333333e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 33%|      | 500/1500 [02:32<04:03,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.293658256530762, 'eval_wer': 1.0, 'eval_runtime': 3.6049, 'eval_samples_per_second': 55.48, 'eval_steps_per_second': 6.935, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tfc/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      " 37%|      | 550/1500 [02:49<04:36,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.0363, 'grad_norm': 16.386117935180664, 'learning_rate': 3.176666666666667e-05, 'epoch': 2.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 600/1500 [03:04<04:06,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.1616, 'grad_norm': 2.575950860977173, 'learning_rate': 3.01e-05, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 650/1500 [03:18<03:51,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.3157, 'grad_norm': 5.570316314697266, 'learning_rate': 2.8433333333333334e-05, 'epoch': 2.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 700/1500 [03:32<03:54,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.717, 'grad_norm': 2.1007020473480225, 'learning_rate': 2.676666666666667e-05, 'epoch': 2.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 750/1500 [03:45<03:05,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.1545, 'grad_norm': 5.170818328857422, 'learning_rate': 2.51e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 50%|     | 750/1500 [03:48<03:05,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.313230514526367, 'eval_wer': 1.0, 'eval_runtime': 3.5318, 'eval_samples_per_second': 56.629, 'eval_steps_per_second': 7.079, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tfc/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      " 53%|    | 800/1500 [04:06<03:11,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.0283, 'grad_norm': 4.516280651092529, 'learning_rate': 2.3433333333333335e-05, 'epoch': 3.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 850/1500 [04:20<03:10,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.2261, 'grad_norm': 4.357248783111572, 'learning_rate': 2.18e-05, 'epoch': 3.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 900/1500 [04:34<02:31,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.453, 'grad_norm': 19.7100772857666, 'learning_rate': 2.0133333333333336e-05, 'epoch': 3.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 950/1500 [04:48<02:35,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.3564, 'grad_norm': 9.602667808532715, 'learning_rate': 1.8466666666666667e-05, 'epoch': 3.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 1000/1500 [05:02<02:10,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.9006, 'grad_norm': 8.760149955749512, 'learning_rate': 1.6800000000000002e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 67%|   | 1000/1500 [05:05<02:10,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.355025768280029, 'eval_wer': 1.0, 'eval_runtime': 3.5516, 'eval_samples_per_second': 56.313, 'eval_steps_per_second': 7.039, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tfc/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      " 70%|   | 1051/1500 [05:22<01:55,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.1488, 'grad_norm': 0.9166431427001953, 'learning_rate': 1.5133333333333333e-05, 'epoch': 4.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 1100/1500 [05:36<01:51,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.9565, 'grad_norm': 1.7678842544555664, 'learning_rate': 1.3466666666666666e-05, 'epoch': 4.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 1150/1500 [05:50<01:49,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.2498, 'grad_norm': 0.9555894136428833, 'learning_rate': 1.18e-05, 'epoch': 4.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 1200/1500 [06:05<01:23,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.9125, 'grad_norm': 2.0177369117736816, 'learning_rate': 1.0133333333333333e-05, 'epoch': 4.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 1250/1500 [06:18<01:00,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.952, 'grad_norm': 1.9424035549163818, 'learning_rate': 8.466666666666666e-06, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 83%| | 1250/1500 [06:22<01:00,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.36012077331543, 'eval_wer': 1.0, 'eval_runtime': 3.5295, 'eval_samples_per_second': 56.666, 'eval_steps_per_second': 7.083, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tfc/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      " 87%| | 1301/1500 [06:38<00:51,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.0425, 'grad_norm': 1.4594476222991943, 'learning_rate': 6.800000000000001e-06, 'epoch': 5.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 1350/1500 [06:52<00:40,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.2433, 'grad_norm': 1.1296777725219727, 'learning_rate': 5.133333333333334e-06, 'epoch': 5.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 1400/1500 [07:06<00:28,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.0715, 'grad_norm': 1.506329894065857, 'learning_rate': 3.466666666666667e-06, 'epoch': 5.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 1450/1500 [07:21<00:12,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.0711, 'grad_norm': 2.138375997543335, 'learning_rate': 1.8e-06, 'epoch': 5.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1500/1500 [07:35<00:00,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.0311, 'grad_norm': 0.991845428943634, 'learning_rate': 1.3333333333333334e-07, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|| 1500/1500 [07:38<00:00,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.36480712890625, 'eval_wer': 1.0, 'eval_runtime': 3.5382, 'eval_samples_per_second': 56.525, 'eval_steps_per_second': 7.066, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1500/1500 [07:41<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 461.9248, 'train_samples_per_second': 25.978, 'train_steps_per_second': 3.247, 'train_loss': 5.279536122639974, 'epoch': 6.0}\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ~/asr_project/asr-train/logs/*\n",
    "\n",
    "model_dir = os.path.expanduser('~/asr_project/asr-train/model_outputs/wav2vec2-finetuned-smol')\n",
    "tokenizer.save_pretrained(model_dir)\n",
    "\n",
    "# Load the processor and model\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-960h\", \n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "# Freeze feature extractor layers\n",
    "model.freeze_feature_encoder()\n",
    "\n",
    "# # Freeze all layers except the head\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False  # Freeze all parameters\n",
    "\n",
    "# # Assuming the head is the `classifier` in Wav2Vec2ForCTC\n",
    "# for param in model.lm_head.parameters():  # For the head (classifier) layer\n",
    "#     param.requires_grad = True  # Unfreeze the head\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=os.path.expanduser('~/asr_project/asr-train/model_outputs'),\n",
    "    logging_dir=os.path.expanduser('~/asr_project/asr-train/logs'),\n",
    "    per_device_train_batch_size=8,              # batch size for training\n",
    "    per_device_eval_batch_size=8,               # batch size for evaluation\n",
    "    num_train_epochs=6,                           # total number of training epochs\n",
    "    logging_steps=50,                            # log every 100 steps\n",
    "    eval_strategy=\"steps\",                  # evaluate during training\n",
    "    save_steps=250,                               # save checkpoint every 500 steps\n",
    "    eval_steps=250,                               # evaluate every 500 steps\n",
    "    load_best_model_at_end=True,                  # load the best model at the end of training\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# # Create the Trainer instance\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=dataset['train'],                  # your training dataset\n",
    "#     eval_dataset=dataset['val'],                      # your validation dataset\n",
    "# )\n",
    "\n",
    "\n",
    "# Define huggingface trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=dataset[\"train\"].select(range(2000)),\n",
    "    eval_dataset=dataset[\"val\"].select(range(200)),\n",
    "    processing_class= processor.feature_extractor\n",
    ")\n",
    "\n",
    "# Start the training\n",
    "trainer.train()\n",
    "\n",
    "# Save the final model\n",
    "trainer.save_model(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LEARNED TO RECOGNIZE OMENS AND FOLLOW THEM THE OLD KING HAD SAID']\n"
     ]
    }
   ],
   "source": [
    "# Load the processor and model\n",
    "model_dir = os.path.expanduser('~/asr_project/asr-train/model_outputs/wav2vec2-finetuned-smol')\n",
    "processor = Wav2Vec2Processor.from_pretrained('facebook/wav2vec2-large-960h')\n",
    "model = Wav2Vec2ForCTC.from_pretrained('facebook/wav2vec2-large-960h')\n",
    "\n",
    "# Load audio file\n",
    "audio_file = \"/home/tfc/asr_project/common_voice/cv-valid-train/cv-valid-train/sample-000000.wav\"  # Replace with your audio file path\n",
    "waveform, sample_rate = torchaudio.load(audio_file)\n",
    "\n",
    "\n",
    "# If the sample rate is not 16kHz, resample it\n",
    "if sample_rate != 16000:\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "    waveform = resampler(waveform)\n",
    "\n",
    "# Convert to the right format for the model\n",
    "input_values = processor(waveform.squeeze().numpy(), sampling_rate=16000, return_tensors=\"pt\").input_values\n",
    "\n",
    "# Get logits from the model\n",
    "with torch.no_grad():\n",
    "    logits = model(input_values).logits\n",
    "\n",
    "# Get predicted ids\n",
    "predicted_ids = logits.argmax(dim=-1)\n",
    "\n",
    "# Decode the predicted ids to text\n",
    "transcription = processor.batch_decode(predicted_ids)\n",
    "\n",
    "print(transcription)  # Print the transcription result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processor and model\n",
    "model_dir = os.path.expanduser('~/asr_project/asr-train/model_outputs/wav2vec2-finetuned-smol')\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_dir)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_dir)\n",
    "\n",
    "# Load audio file\n",
    "audio_file = \"/home/tfc/asr_project/common_voice/cv-valid-train/cv-valid-train/sample-000000.wav\"  # Replace with your audio file path\n",
    "waveform, sample_rate = torchaudio.load(audio_file)\n",
    "\n",
    "\n",
    "# If the sample rate is not 16kHz, resample it\n",
    "if sample_rate != 16000:\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "    waveform = resampler(waveform)\n",
    "\n",
    "# Convert to the right format for the model\n",
    "input_values = processor(waveform.squeeze().numpy(), sampling_rate=16000, return_tensors=\"pt\").input_values\n",
    "\n",
    "# Get logits from the model\n",
    "with torch.no_grad():\n",
    "    logits = model(input_values).logits\n",
    "\n",
    "# Get predicted ids\n",
    "predicted_ids = logits.argmax(dim=-1)\n",
    "\n",
    "# Decode the predicted ids to text\n",
    "transcription = processor.batch_decode(predicted_ids)\n",
    "\n",
    "print(transcription)  # Print the transcription result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File locations assumed in parent directory\n",
    "transcription_file = os.path.expanduser(\n",
    "    '~/asr_project/common_voice/cv-valid-train.csv')              # Transcription file location\n",
    "audio_folder = os.path.expanduser(\n",
    "    '~/asr_project/common_voice/cv-valid-train')   # Audio files directory\n",
    "df = pd.read_csv(transcription_file)[['filename','text']]         # Read transcription file\n",
    "\n",
    "# Convert mp3 to wav. Change mp3 file extension in df accordingly\n",
    "df['filename'] = df['filename'].apply(\n",
    "    lambda filename: convert_mp3_to_wav(\n",
    "        os.path.join(audio_folder, filename)))\n",
    "df.to_csv('temp.csv',index=False)                                 # Save temp copy of csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing log history to find train and val losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for log in trainer.state.log_history:\n",
    "    if 'loss' in log:\n",
    "        train_losses.append(log['loss'])  # Training loss\n",
    "    if 'eval_loss' in log:\n",
    "        val_losses.append(log['eval_loss'])  # Validation loss\n",
    "\n",
    "# Get the final train and val losses\n",
    "final_train_loss = train_losses[-1] if train_losses else None\n",
    "final_val_loss = val_losses[-1] if val_losses else None\n",
    "\n",
    "print(f\"Final Training Loss: {final_train_loss}\")\n",
    "print(f\"Final Validation Loss: {final_val_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 16.7967,\n",
       "  'grad_norm': 6.2722487449646,\n",
       "  'learning_rate': 4.8433333333333336e-05,\n",
       "  'epoch': 0.2,\n",
       "  'step': 50},\n",
       " {'loss': 15.7987,\n",
       "  'grad_norm': 14.26067066192627,\n",
       "  'learning_rate': 4.676666666666667e-05,\n",
       "  'epoch': 0.4,\n",
       "  'step': 100},\n",
       " {'loss': 14.7088,\n",
       "  'grad_norm': 12.909340858459473,\n",
       "  'learning_rate': 4.5100000000000005e-05,\n",
       "  'epoch': 0.6,\n",
       "  'step': 150},\n",
       " {'loss': 13.7017,\n",
       "  'grad_norm': 13.007761001586914,\n",
       "  'learning_rate': 4.3433333333333336e-05,\n",
       "  'epoch': 0.8,\n",
       "  'step': 200},\n",
       " {'loss': 13.6914,\n",
       "  'grad_norm': 4.1002326011657715,\n",
       "  'learning_rate': 4.176666666666667e-05,\n",
       "  'epoch': 1.0,\n",
       "  'step': 250},\n",
       " {'eval_loss': 27.835580825805664,\n",
       "  'eval_wer': 1.0,\n",
       "  'eval_runtime': 3.6111,\n",
       "  'eval_samples_per_second': 55.385,\n",
       "  'eval_steps_per_second': 6.923,\n",
       "  'epoch': 1.0,\n",
       "  'step': 250},\n",
       " {'loss': 13.462,\n",
       "  'grad_norm': 4.646790027618408,\n",
       "  'learning_rate': 4.013333333333333e-05,\n",
       "  'epoch': 1.2,\n",
       "  'step': 300},\n",
       " {'loss': 11.7557,\n",
       "  'grad_norm': 4.622196674346924,\n",
       "  'learning_rate': 3.846666666666667e-05,\n",
       "  'epoch': 1.4,\n",
       "  'step': 350},\n",
       " {'loss': 12.614,\n",
       "  'grad_norm': 4.976258754730225,\n",
       "  'learning_rate': 3.68e-05,\n",
       "  'epoch': 1.6,\n",
       "  'step': 400},\n",
       " {'loss': 10.9404,\n",
       "  'grad_norm': 4.094659328460693,\n",
       "  'learning_rate': 3.513333333333334e-05,\n",
       "  'epoch': 1.8,\n",
       "  'step': 450},\n",
       " {'loss': 11.3359,\n",
       "  'grad_norm': 5.993251323699951,\n",
       "  'learning_rate': 3.346666666666667e-05,\n",
       "  'epoch': 2.0,\n",
       "  'step': 500},\n",
       " {'eval_loss': 22.044719696044922,\n",
       "  'eval_wer': 1.0,\n",
       "  'eval_runtime': 3.533,\n",
       "  'eval_samples_per_second': 56.609,\n",
       "  'eval_steps_per_second': 7.076,\n",
       "  'epoch': 2.0,\n",
       "  'step': 500},\n",
       " {'loss': 10.8266,\n",
       "  'grad_norm': 6.041836738586426,\n",
       "  'learning_rate': 3.18e-05,\n",
       "  'epoch': 2.2,\n",
       "  'step': 550},\n",
       " {'loss': 10.4617,\n",
       "  'grad_norm': 12.995034217834473,\n",
       "  'learning_rate': 3.0133333333333335e-05,\n",
       "  'epoch': 2.4,\n",
       "  'step': 600},\n",
       " {'loss': 10.4243,\n",
       "  'grad_norm': 15.00837230682373,\n",
       "  'learning_rate': 2.846666666666667e-05,\n",
       "  'epoch': 2.6,\n",
       "  'step': 650},\n",
       " {'loss': 10.2075,\n",
       "  'grad_norm': 9.03986644744873,\n",
       "  'learning_rate': 2.6800000000000004e-05,\n",
       "  'epoch': 2.8,\n",
       "  'step': 700},\n",
       " {'loss': 10.0827,\n",
       "  'grad_norm': 15.079448699951172,\n",
       "  'learning_rate': 2.5133333333333336e-05,\n",
       "  'epoch': 3.0,\n",
       "  'step': 750},\n",
       " {'eval_loss': 18.793865203857422,\n",
       "  'eval_wer': 1.0,\n",
       "  'eval_runtime': 3.5767,\n",
       "  'eval_samples_per_second': 55.918,\n",
       "  'eval_steps_per_second': 6.99,\n",
       "  'epoch': 3.0,\n",
       "  'step': 750},\n",
       " {'loss': 9.7775,\n",
       "  'grad_norm': 21.855064392089844,\n",
       "  'learning_rate': 2.3466666666666667e-05,\n",
       "  'epoch': 3.2,\n",
       "  'step': 800},\n",
       " {'loss': 9.4847,\n",
       "  'grad_norm': 2.979792833328247,\n",
       "  'learning_rate': 2.18e-05,\n",
       "  'epoch': 3.4,\n",
       "  'step': 850},\n",
       " {'loss': 9.7087,\n",
       "  'grad_norm': 9.167875289916992,\n",
       "  'learning_rate': 2.0133333333333336e-05,\n",
       "  'epoch': 3.6,\n",
       "  'step': 900},\n",
       " {'loss': 9.5989,\n",
       "  'grad_norm': 4.922226428985596,\n",
       "  'learning_rate': 1.8466666666666667e-05,\n",
       "  'epoch': 3.8,\n",
       "  'step': 950},\n",
       " {'loss': 9.5164,\n",
       "  'grad_norm': 3.8449289798736572,\n",
       "  'learning_rate': 1.6800000000000002e-05,\n",
       "  'epoch': 4.0,\n",
       "  'step': 1000},\n",
       " {'eval_loss': 16.941381454467773,\n",
       "  'eval_wer': 1.0,\n",
       "  'eval_runtime': 3.521,\n",
       "  'eval_samples_per_second': 56.803,\n",
       "  'eval_steps_per_second': 7.1,\n",
       "  'epoch': 4.0,\n",
       "  'step': 1000},\n",
       " {'loss': 9.696,\n",
       "  'grad_norm': 4.975978851318359,\n",
       "  'learning_rate': 1.5133333333333333e-05,\n",
       "  'epoch': 4.2,\n",
       "  'step': 1050},\n",
       " {'loss': 9.2756,\n",
       "  'grad_norm': 21.673755645751953,\n",
       "  'learning_rate': 1.3466666666666666e-05,\n",
       "  'epoch': 4.4,\n",
       "  'step': 1100},\n",
       " {'loss': 9.081,\n",
       "  'grad_norm': 4.036062240600586,\n",
       "  'learning_rate': 1.18e-05,\n",
       "  'epoch': 4.6,\n",
       "  'step': 1150},\n",
       " {'loss': 9.3539,\n",
       "  'grad_norm': 7.174581527709961,\n",
       "  'learning_rate': 1.0133333333333333e-05,\n",
       "  'epoch': 4.8,\n",
       "  'step': 1200},\n",
       " {'loss': 8.8351,\n",
       "  'grad_norm': 6.265654563903809,\n",
       "  'learning_rate': 8.466666666666666e-06,\n",
       "  'epoch': 5.0,\n",
       "  'step': 1250},\n",
       " {'eval_loss': 16.06525421142578,\n",
       "  'eval_wer': 1.0,\n",
       "  'eval_runtime': 3.5364,\n",
       "  'eval_samples_per_second': 56.554,\n",
       "  'eval_steps_per_second': 7.069,\n",
       "  'epoch': 5.0,\n",
       "  'step': 1250},\n",
       " {'loss': 9.3105,\n",
       "  'grad_norm': 23.709131240844727,\n",
       "  'learning_rate': 6.800000000000001e-06,\n",
       "  'epoch': 5.2,\n",
       "  'step': 1300},\n",
       " {'loss': 9.2973,\n",
       "  'grad_norm': 2.643524408340454,\n",
       "  'learning_rate': 5.133333333333334e-06,\n",
       "  'epoch': 5.4,\n",
       "  'step': 1350},\n",
       " {'loss': 9.16,\n",
       "  'grad_norm': 5.100998878479004,\n",
       "  'learning_rate': 3.466666666666667e-06,\n",
       "  'epoch': 5.6,\n",
       "  'step': 1400},\n",
       " {'loss': 8.7047,\n",
       "  'grad_norm': 3.4133598804473877,\n",
       "  'learning_rate': 1.8e-06,\n",
       "  'epoch': 5.8,\n",
       "  'step': 1450},\n",
       " {'loss': 9.0332,\n",
       "  'grad_norm': 3.391388416290283,\n",
       "  'learning_rate': 1.3333333333333334e-07,\n",
       "  'epoch': 6.0,\n",
       "  'step': 1500},\n",
       " {'eval_loss': 15.793719291687012,\n",
       "  'eval_wer': 1.0,\n",
       "  'eval_runtime': 3.5108,\n",
       "  'eval_samples_per_second': 56.966,\n",
       "  'eval_steps_per_second': 7.121,\n",
       "  'epoch': 6.0,\n",
       "  'step': 1500},\n",
       " {'train_runtime': 391.4636,\n",
       "  'train_samples_per_second': 30.654,\n",
       "  'train_steps_per_second': 3.832,\n",
       "  'total_flos': 2.684085326967472e+18,\n",
       "  'train_loss': 10.888052510579428,\n",
       "  'epoch': 6.0,\n",
       "  'step': 1500}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tfc/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/configuration_utils.py:306: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['lm_head.bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 32\n",
      "Sample vocabulary items:\n",
      "Token: <pad>, Index: 0\n",
      "Token: <s>, Index: 1\n",
      "Token: </s>, Index: 2\n",
      "Token: <unk>, Index: 3\n",
      "Token: |, Index: 4\n",
      "Token: E, Index: 5\n",
      "Token: T, Index: 6\n",
      "Token: A, Index: 7\n",
      "Token: O, Index: 8\n",
      "Token: N, Index: 9\n",
      "Token: I, Index: 10\n",
      "Token: H, Index: 11\n",
      "Token: S, Index: 12\n",
      "Token: R, Index: 13\n",
      "Token: D, Index: 14\n",
      "Token: L, Index: 15\n",
      "Token: U, Index: 16\n",
      "Token: M, Index: 17\n",
      "Token: W, Index: 18\n",
      "Token: C, Index: 19\n",
      "Token: F, Index: 20\n",
      "Token: G, Index: 21\n",
      "Token: Y, Index: 22\n",
      "Token: P, Index: 23\n",
      "Token: B, Index: 24\n",
      "Token: V, Index: 25\n",
      "Token: K, Index: 26\n",
      "Token: ', Index: 27\n",
      "Token: X, Index: 28\n",
      "Token: J, Index: 29\n",
      "Token: Q, Index: 30\n",
      "Token: Z, Index: 31\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "\n",
    "# Load the processor and model\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-base\", \n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "# Access the vocabulary\n",
    "vocab = processor.tokenizer.get_vocab()\n",
    "\n",
    "# Print the vocabulary size and a sample of the vocabulary\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n",
    "print(\"Sample vocabulary items:\")\n",
    "for token, index in list(vocab.items()):  # Print the first 10 tokens\n",
    "    print(f\"Token: {token}, Index: {index}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/51393 [00:00<?, ?it/s]/home/tfc/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "  0%|          | 50/51393 [00:13<3:40:37,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 16.6252, 'grad_norm': 6.919604778289795, 'learning_rate': 4.995427392835601e-05, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 100/51393 [00:25<3:40:29,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 15.7953, 'grad_norm': 5.722819805145264, 'learning_rate': 4.990562917128792e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 150/51393 [00:38<3:56:36,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 15.4045, 'grad_norm': 5.995153903961182, 'learning_rate': 4.9856984414219837e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 200/51393 [00:51<3:03:57,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 14.2438, 'grad_norm': 4.1416754722595215, 'learning_rate': 4.980833965715175e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 251/51393 [01:03<2:57:46,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 12.9417, 'grad_norm': 10.482752799987793, 'learning_rate': 4.975969490008367e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 300/51393 [01:16<3:45:51,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 12.661, 'grad_norm': 9.821016311645508, 'learning_rate': 4.9712023038156955e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 351/51393 [01:29<3:09:16,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 12.0799, 'grad_norm': 5.653285980224609, 'learning_rate': 4.966337828108887e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 401/51393 [01:42<2:58:17,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 11.4288, 'grad_norm': 5.822386741638184, 'learning_rate': 4.961473352402078e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 451/51393 [01:54<3:54:32,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 11.6048, 'grad_norm': 8.978076934814453, 'learning_rate': 4.95660887669527e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 500/51393 [02:07<4:07:09,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 11.1998, 'grad_norm': 8.123398780822754, 'learning_rate': 4.951744400988462e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacity of 15.69 GiB of which 1.63 GiB is free. Process 1941 has 249.95 MiB memory in use. Including non-PyTorch memory, this process has 13.38 GiB memory in use. Of the allocated memory 10.55 GiB is allocated by PyTorch, and 2.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 60\u001b[0m\n\u001b[1;32m     49\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     50\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     51\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m     processing_class\u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mfeature_extractor\n\u001b[1;32m     57\u001b[0m )\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Start the training\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Save the final model\u001b[39;00m\n\u001b[1;32m     63\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m~/asr_project/asr-train/model_outputs/wav2vec2-finetuned-final\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/trainer.py:2122\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2120\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2123\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/trainer.py:2541\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2540\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2541\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2542\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2543\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/trainer.py:2997\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2995\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2996\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 2997\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2999\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m   3000\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_checkpoint(model, trial, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/trainer.py:2951\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   2950\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 2951\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2952\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2954\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/trainer.py:3964\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3961\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3963\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3964\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3965\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3967\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3974\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/trainer.py:4158\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4155\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[1;32m   4157\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 4158\u001b[0m losses, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4159\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4160\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   4161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4162\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/trainer.py:4374\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   4372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[1;32m   4373\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 4374\u001b[0m         loss, outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   4375\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m   4377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/trainer.py:3625\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3623\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3624\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3625\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3626\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/accelerate/utils/operations.py:823\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/accelerate/utils/operations.py:811\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 811\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/amp/autocast_mode.py:44\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:2229\u001b[0m, in \u001b[0;36mWav2Vec2ForCTC.forward\u001b[0;34m(self, input_values, attention_mask, output_attentions, output_hidden_states, return_dict, labels)\u001b[0m\n\u001b[1;32m   2226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvocab_size:\n\u001b[1;32m   2227\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel values must be <= vocab_size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvocab_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2229\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwav2vec2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2230\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2232\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2235\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2237\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   2238\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1810\u001b[0m, in \u001b[0;36mWav2Vec2Model.forward\u001b[0;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1805\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1806\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m   1807\u001b[0m )\n\u001b[1;32m   1808\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1810\u001b[0m extract_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1811\u001b[0m extract_features \u001b[38;5;241m=\u001b[39m extract_features\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1814\u001b[0m     \u001b[38;5;66;03m# compute reduced attention_mask corresponding to feature vectors\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:464\u001b[0m, in \u001b[0;36mWav2Vec2FeatureEncoder.forward\u001b[0;34m(self, input_values)\u001b[0m\n\u001b[1;32m    459\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    460\u001b[0m             conv_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    461\u001b[0m             hidden_states,\n\u001b[1;32m    462\u001b[0m         )\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mconv_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:362\u001b[0m, in \u001b[0;36mWav2Vec2GroupNormConvLayer.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[1;32m    361\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(hidden_states)\n\u001b[0;32m--> 362\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(hidden_states)\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/modules/normalization.py:313\u001b[0m, in \u001b[0;36mGroupNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/functional.py:2955\u001b[0m, in \u001b[0;36mgroup_norm\u001b[0;34m(input, num_groups, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2948\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2949\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected at least 2 dimensions for input tensor but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2950\u001b[0m     )\n\u001b[1;32m   2951\u001b[0m _verify_batch_size(\n\u001b[1;32m   2952\u001b[0m     [\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_groups, num_groups]\n\u001b[1;32m   2953\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m2\u001b[39m:])\n\u001b[1;32m   2954\u001b[0m )\n\u001b[0;32m-> 2955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2956\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacity of 15.69 GiB of which 1.63 GiB is free. Process 1941 has 249.95 MiB memory in use. Including non-PyTorch memory, this process has 13.38 GiB memory in use. Of the allocated memory 10.55 GiB is allocated by PyTorch, and 2.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "!rm -rf ~/asr_project/asr-train/logs/*\n",
    "\n",
    "# Load the processor and model\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-960h\", \n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "# Freeze feature extractor layers\n",
    "# model.freeze_feature_encoder()\n",
    "\n",
    "# Freeze all layers except the head\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # Freeze all parameters\n",
    "\n",
    "# Assuming the head is the `classifier` in Wav2Vec2ForCTC\n",
    "for param in model.lm_head.parameters():  # For the head (classifier) layer\n",
    "    param.requires_grad = True  # Unfreeze the head\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=os.path.expanduser('~/asr_project/asr-train/model_outputs'),\n",
    "    logging_dir=os.path.expanduser('~/asr_project/asr-train/logs'),\n",
    "    per_device_train_batch_size=8,              # batch size for training\n",
    "    per_device_eval_batch_size=8,               # batch size for evaluation\n",
    "    num_train_epochs=3,                           # total number of training epochs\n",
    "    logging_steps=50,                            # log every 100 steps\n",
    "    eval_strategy=\"steps\",                  # evaluate during training\n",
    "    save_steps=500,                               # save checkpoint every 500 steps\n",
    "    eval_steps=500,                               # evaluate every 500 steps\n",
    "    load_best_model_at_end=True,                  # load the best model at the end of training\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# # Create the Trainer instance\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=dataset['train'],                  # your training dataset\n",
    "#     eval_dataset=dataset['val'],                      # your validation dataset\n",
    "# )\n",
    "\n",
    "\n",
    "# Define huggingface trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"val\"],\n",
    "    processing_class= processor.feature_extractor\n",
    ")\n",
    "\n",
    "# Start the training\n",
    "trainer.train()\n",
    "\n",
    "# Save the final model\n",
    "trainer.save_model(os.path.expanduser('~/asr_project/asr-train/model_outputs/wav2vec2-finetuned-final'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 315461792\n"
     ]
    }
   ],
   "source": [
    "# Load the processor and model\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-960h\", \n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "# Function to count trainable parameters\n",
    "def count_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Get the number of trainable parameters\n",
    "num_trainable_params = count_trainable_parameters(model)\n",
    "\n",
    "print(f'Number of trainable parameters: {num_trainable_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 311261344\n"
     ]
    }
   ],
   "source": [
    "# Load the processor and model\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-960h\", \n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "model.freeze_feature_encoder()\n",
    "\n",
    "# Function to count trainable parameters\n",
    "def count_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Get the number of trainable parameters\n",
    "num_trainable_params = count_trainable_parameters(model)\n",
    "\n",
    "print(f'Number of trainable parameters: {num_trainable_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 32800\n"
     ]
    }
   ],
   "source": [
    "# Load the processor and model\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-960h\", \n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "# Freeze all layers except the head\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # Freeze all parameters\n",
    "\n",
    "# Assuming the head is the `classifier` in Wav2Vec2ForCTC\n",
    "for param in model.lm_head.parameters():  # For the head (classifier) layer\n",
    "    param.requires_grad = True  # Unfreeze the head\n",
    "\n",
    "# Function to count trainable parameters\n",
    "def count_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Get the number of trainable parameters\n",
    "num_trainable_params = count_trainable_parameters(model)\n",
    "\n",
    "print(f'Number of trainable parameters: {num_trainable_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Importing pretrained checkpoint\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-960h\", \n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "# Freeze all parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the parameters in the head\n",
    "for param in model.lm_head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Defining training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=os.path.expanduser('~/asr_project/asr-train/model_outputs'),\n",
    "    logging_dir=os.path.expanduser('~/asr_project/asr-train/logs'),\n",
    "    group_by_length=True,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_strategy = \"steps\",\n",
    "    eval_strategy=\"steps\",\n",
    "    num_train_epochs=30,\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=True,\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    logging_steps=1,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.005,\n",
    "    warmup_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    # report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "# Define huggingface trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"val\"],\n",
    "    processing_class= processor.feature_extractor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1/30:   0%|          | 0/17131 [00:00<?, ?it/s]/home/tfc/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Epoch 1/30:   6%|         | 999/17131 [03:16<52:51,  5.09it/s, train_loss=26.8]  \n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 6.60 GiB. GPU 0 has a total capacity of 15.69 GiB of which 3.30 GiB is free. Process 1941 has 249.95 MiB memory in use. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.19 GiB is allocated by PyTorch, and 293.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Forward pass with mixed precision\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 50\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:2229\u001b[0m, in \u001b[0;36mWav2Vec2ForCTC.forward\u001b[0;34m(self, input_values, attention_mask, output_attentions, output_hidden_states, return_dict, labels)\u001b[0m\n\u001b[1;32m   2226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvocab_size:\n\u001b[1;32m   2227\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel values must be <= vocab_size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvocab_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2229\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwav2vec2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2230\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2232\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2235\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2237\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   2238\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1810\u001b[0m, in \u001b[0;36mWav2Vec2Model.forward\u001b[0;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1805\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1806\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m   1807\u001b[0m )\n\u001b[1;32m   1808\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1810\u001b[0m extract_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1811\u001b[0m extract_features \u001b[38;5;241m=\u001b[39m extract_features\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1814\u001b[0m     \u001b[38;5;66;03m# compute reduced attention_mask corresponding to feature vectors\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:464\u001b[0m, in \u001b[0;36mWav2Vec2FeatureEncoder.forward\u001b[0;34m(self, input_values)\u001b[0m\n\u001b[1;32m    459\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    460\u001b[0m             conv_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    461\u001b[0m             hidden_states,\n\u001b[1;32m    462\u001b[0m         )\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mconv_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:362\u001b[0m, in \u001b[0;36mWav2Vec2GroupNormConvLayer.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[1;32m    361\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(hidden_states)\n\u001b[0;32m--> 362\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(hidden_states)\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/modules/normalization.py:313\u001b[0m, in \u001b[0;36mGroupNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/torch/nn/functional.py:2955\u001b[0m, in \u001b[0;36mgroup_norm\u001b[0;34m(input, num_groups, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2948\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2949\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected at least 2 dimensions for input tensor but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2950\u001b[0m     )\n\u001b[1;32m   2951\u001b[0m _verify_batch_size(\n\u001b[1;32m   2952\u001b[0m     [\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_groups, num_groups]\n\u001b[1;32m   2953\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m2\u001b[39m:])\n\u001b[1;32m   2954\u001b[0m )\n\u001b[0;32m-> 2955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2956\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 6.60 GiB. GPU 0 has a total capacity of 15.69 GiB of which 3.30 GiB is free. Process 1941 has 249.95 MiB memory in use. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.19 GiB is allocated by PyTorch, and 293.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(log_dir=os.path.expanduser('~/asr_project/asr-train/logs'))\n",
    "\n",
    "num_epochs = 30\n",
    "num_warmup_steps = 1000\n",
    "num_log_steps = 100\n",
    "\n",
    "# Importing pretrained checkpoint\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-960h\", \n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "# Freeze all parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the parameters in the head\n",
    "for param in model.lm_head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Set up DataLoader for training and validation sets\n",
    "train_dataloader = DataLoader(dataset[\"train\"], batch_size=8, shuffle=True, collate_fn=data_collator)\n",
    "val_dataloader = DataLoader(dataset[\"val\"], batch_size=8, shuffle=False, collate_fn=data_collator)\n",
    "\n",
    "# Initialize optimizer and gradient scaler for mixed precision\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=0.005)\n",
    "scaler = torch.amp.GradScaler()  # For mixed precision training\n",
    "\n",
    "# Scheduler\n",
    "num_training_steps = len(train_dataloader) * num_epochs  # epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n",
    "\n",
    "# Training and evaluation loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "global_step = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    with tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\") as progress_bar:\n",
    "        for batch in progress_bar:\n",
    "            # Move data to the device\n",
    "            input_values = batch[\"input_values\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            # Forward pass with mixed precision\n",
    "            with autocast(device_type=\"cuda\"):\n",
    "                outputs = model(input_values, labels=labels)\n",
    "                loss = outputs.loss\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # Logging\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({\"train_loss\": total_loss / (progress_bar.n + 1)})\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % 20 == 0:\n",
    "                writer.add_scalar(\"train/loss\", total_loss/ (progress_bar.n + 1), global_step)\n",
    "\n",
    "    writer.add_scalar(\"train/loss\", total_loss.item()/ len(train_dataloader), global_step)\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            input_values = batch[\"input_values\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            with autocast(device_type=\"cuda\"):\n",
    "                outputs = model(input_values, labels=labels)\n",
    "                val_loss += outputs.loss.item()\n",
    "\n",
    "    writer.add_scalar(\"train/loss\", val_loss/ len(val_dataloader), global_step)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} - Training Loss: {total_loss / len(train_dataloader):.4f}, Validation Loss: {val_loss / len(val_dataloader):.4f}\")\n",
    "\n",
    "    # Save checkpoint\n",
    "    model_dir = os.path.expanduser(\"~/asr_project/asr-train/model_outputs\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model.save_pretrained(model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/trainer.py:2122\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2120\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2123\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/trainer.py:2151\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2149\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently training with a batch size of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2150\u001b[0m \u001b[38;5;66;03m# Data loader and number of training steps\u001b[39;00m\n\u001b[0;32m-> 2151\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_train_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fsdp_xla_v2_enabled:\n\u001b[1;32m   2153\u001b[0m     train_dataloader \u001b[38;5;241m=\u001b[39m tpu_spmd_dataloader(train_dataloader)\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/trainer.py:970\u001b[0m, in \u001b[0;36mTrainer.get_train_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    961\u001b[0m dataloader_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size,\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollate_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m: data_collator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpersistent_workers\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdataloader_persistent_workers,\n\u001b[1;32m    967\u001b[0m }\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(train_dataset, torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterableDataset):\n\u001b[0;32m--> 970\u001b[0m     dataloader_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampler\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_train_sampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    971\u001b[0m     dataloader_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_last\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdataloader_drop_last\n\u001b[1;32m    972\u001b[0m     dataloader_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker_init_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m seed_worker\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/trainer.py:932\u001b[0m, in \u001b[0;36mTrainer._get_train_sampler\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    928\u001b[0m         lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    929\u001b[0m     model_input_name \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    930\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessing_class\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessing_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    931\u001b[0m     )\n\u001b[0;32m--> 932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLengthGroupedSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlengths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_input_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m RandomSampler(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset)\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/transformers/trainer_pt_utils.py:650\u001b[0m, in \u001b[0;36mLengthGroupedSampler.__init__\u001b[0;34m(self, batch_size, dataset, lengths, model_input_name, generator)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    643\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(dataset[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset[\u001b[38;5;241m0\u001b[39m], BatchEncoding))\n\u001b[1;32m    644\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m model_input_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dataset[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    645\u001b[0m     ):\n\u001b[1;32m    646\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    647\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only automatically infer lengths for datasets whose items are dictionaries with an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    648\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_input_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m key.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    649\u001b[0m         )\n\u001b[0;32m--> 650\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(feature[model_input_name]) \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m dataset]\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(lengths, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    652\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    653\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf lengths is a torch.Tensor, LengthGroupedSampler will be slow. Converting lengths to List[int]...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    654\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/datasets/arrow_dataset.py:2372\u001b[0m, in \u001b[0;36mDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2370\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(pa_subtable\u001b[38;5;241m.\u001b[39mnum_rows):\n\u001b[1;32m   2371\u001b[0m             pa_subtable_ex \u001b[38;5;241m=\u001b[39m pa_subtable\u001b[38;5;241m.\u001b[39mslice(i, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 2372\u001b[0m             formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2373\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpa_subtable_ex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2374\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2375\u001b[0m \u001b[43m                \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2376\u001b[0m \u001b[43m                \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2377\u001b[0m \u001b[43m                \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_all_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2378\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2379\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m formatted_output\n\u001b[1;32m   2380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/datasets/formatting/formatting.py:639\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    637\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/datasets/formatting/formatting.py:403\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/datasets/formatting/formatting.py:443\u001b[0m, in \u001b[0;36mPythonFormatter.format_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyRow(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 443\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_arrow_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_row(row)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.12/site-packages/datasets/formatting/formatting.py:145\u001b[0m, in \u001b[0;36mPythonArrowExtractor.extract_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unnest(\u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pydict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract losses and epochs\n",
    "epochs = []\n",
    "train_losses = []\n",
    "eval_losses = []\n",
    "\n",
    "training_logs = trainer.state.log_history\n",
    "\n",
    "for log in training_logs:\n",
    "    if 'loss' in log:  # Training loss\n",
    "        train_losses.append(log['loss'])\n",
    "        epochs.append(log['epoch'])\n",
    "    if 'eval_loss' in log:  # Validation loss\n",
    "        eval_losses.append(log['eval_loss'])\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(epochs[:len(train_losses)], train_losses, label=\"Training Loss\")\n",
    "plt.plot(epochs[:len(eval_losses)], eval_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training and Validation Loss over Epochs\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
